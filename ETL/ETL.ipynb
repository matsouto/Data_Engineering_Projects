{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ac285b0-0414-4f98-96a2-a1e53795108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = './data/'\n",
    "log_file = 'log_file.csv'\n",
    "target_file = 'transformed_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(filepath):\n",
    "  df = pd.DataFrame(columns=['name', 'height', 'weight', 'from'])\n",
    "  df = pd.concat([pd.read_csv(filepath), df], ignore_index=True)\n",
    "  df['from'] = '.csv'\n",
    "\n",
    "  return df\n",
    "\n",
    "def extract_from_xml(filepath):\n",
    "  df = pd.DataFrame(columns=['name', 'height', 'weight', 'from'])\n",
    "  tree = ET.parse(filepath)\n",
    "  root = tree.getroot()\n",
    "  for person in root:\n",
    "    _df = pd.DataFrame()\n",
    "    name = person.find('name').text\n",
    "    height = float(person.find('height').text)\n",
    "    weight = float(person.find('weight').text)\n",
    "    _from = '.xml'\n",
    "    _df = pd.DataFrame([{'name': name, 'height': height, 'weight': weight, 'from': _from}])\n",
    "    df = pd.concat([df,_df], ignore_index=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def extract_from_json(filepath):\n",
    "  df = pd.DataFrame(columns=['name', 'height', 'weight', 'from'])\n",
    "  df = pd.concat([pd.read_json(filepath), df], ignore_index=True)\n",
    "  df['from'] = '.json'\n",
    "\n",
    "  return df\n",
    "\n",
    "def extract(datapath):\n",
    "  extracted_data = pd.DataFrame(columns=['name', 'height', 'weight', 'from'])\n",
    "\n",
    "  # Get csv files using glob\n",
    "  for csvfilepath in glob.glob(os.path.join(_path, '*.csv')):\n",
    "    _df = extract_from_csv(csvfilepath)\n",
    "    extracted_data = pd.concat([_df, extracted_data], ignore_index=True)\n",
    "  \n",
    "  # Get json files using glob\n",
    "  for jsonfilepath in glob.glob(os.path.join(_path, '*.json')):\n",
    "    _df = extract_from_json(jsonfilepath)\n",
    "    extracted_data = pd.concat([_df, extracted_data], ignore_index=True)\n",
    "\n",
    "  # Get xml files using glob\n",
    "  for xmlfilepath in glob.glob(os.path.join(_path, '*.xml')):\n",
    "    _df = extract_from_xml(xmlfilepath)\n",
    "    extracted_data = pd.concat([_df, extracted_data], ignore_index=True)\n",
    "\n",
    "  return extracted_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 : Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "  data = data.copy()\n",
    "\n",
    "  ''' Remove duplicates ''' \n",
    "  data.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "  ''' Standardize some measurement units '''\n",
    "  data['height'] = round(data.height * 0.0254, 2)\n",
    "  data['weight'] = round(data.weight * 0.45359237, 2)\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 : Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data, str: target_file):\n",
    "  data.to_csv(target_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 : Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "     name  height  weight   from\n",
      "0   simon    1.72   50.97   .xml\n",
      "1   jacob    1.70   54.73   .xml\n",
      "2   cindy    1.69   57.81   .xml\n",
      "3    ivan    1.72   51.77   .xml\n",
      "4    jack    1.74   55.93  .json\n",
      "5     tom    1.77   64.18  .json\n",
      "6   tracy    1.78   61.90  .json\n",
      "7    john    1.72   50.97  .json\n",
      "8    alex    1.67   51.25   .csv\n",
      "9    ajay    1.82   61.91   .csv\n",
      "10  alice    1.76   69.41   .csv\n",
      "11   ravi    1.73   64.56   .csv\n",
      "12    joe    1.72   65.45   .csv\n"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract(_path) \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load(transformed_data, target_file) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
